{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hT4dpUomperiJJeqV0raIG9YTlSKitkN",
      "authorship_tag": "ABX9TyOMiRnJXK5qeBl0jzGV+b+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EbsHirani/redditChatbot/blob/master/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWtbF66VQXdR",
        "colab_type": "code",
        "outputId": "27c0361c-955d-4e73-d583-5268a5296185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "#os.chdir('drive/My Drive/')\n",
        "#os.mkdir('chatbot')\n",
        "os.chdir('chatbot')\n",
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RC_2015-08.bz2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVo06ka1P9y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sqlite3\n",
        "import json\n",
        "from datetime import datetime\n",
        "timeframe = '2015-08'\n",
        "connection = sqlite3.connect(f\"{timeframe}.db\")\n",
        "c = connection.cursor()\n",
        "c.execute(\"create table if not exists parent_reply(parent_id text primary key, comment_id text unique, parent text, comment text, subreddit text, unix int, score int )\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IRrBYDWcMmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query_list= []\n",
        "row_counter = 0\n",
        "pairs = 0\n",
        "def format_data(data):\n",
        "  data = data.replace(\"\\n\",' newline ').replace('\\r',' newline ').replace('\"',\"'\")\n",
        "def find_parent(parent_id):\n",
        "  query = f\"select comment from parent_reply where comment_id = '{parent_id}' limit 1\"\n",
        "  try:\n",
        "    c.execute(query)\n",
        "    result = c.fetchone()\n",
        "    if result != None:\n",
        "      return result[0]\n",
        "    else:  \n",
        "      return False\n",
        "  except Exception as e:  \n",
        "     return False \n",
        "def find_existing_parent(parent_id):\n",
        "  query = f\"select score from parent_reply where parent_id = '{parent_id}' limit 1\"\n",
        "  try:\n",
        "    c.execute(query)\n",
        "    result = c.fetchone()\n",
        "    if result != None:\n",
        "      return result[0]\n",
        "    else:  \n",
        "      return False\n",
        "  except Exception as e:  \n",
        "     return False \n",
        "def acceptable(data):\n",
        "  if len(data.split(\" \")) > 50 or len(data.split(\" \")) < 1:\n",
        "    return False\n",
        "  elif  len(data) > 1000:\n",
        "    return False\n",
        "  elif data == '[deleted]' or data == '[removed]':\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "def add_query(query):\n",
        "  global query_list\n",
        "  query_list.append(query)\n",
        "  if len(query_list) > 1000:\n",
        "    c.execute(\"begin transaction\")\n",
        "    for query in query_list:\n",
        "      try :\n",
        "        c.execute(query)\n",
        "      except Exception as e:\n",
        "        print('error in ' + query)\n",
        "    connection.commit()\n",
        "    query_list = []\n",
        "\n",
        "\n",
        "\n",
        "def insert_has_parent(comment_id, parent_id, parent_data, body, subreddit, created_utc, score):\n",
        "  try:\n",
        "    query = f\"insert into table parent_reply values({parent_id}, {comment_id}, {parent_data}, {body}, {subreddit}, {int(created_utc)}, {score})\"\n",
        "    add_query(query)\n",
        "  except Exception as e:\n",
        "    print(\"parent insert error\")\n",
        "def insert_no_parent(comment_id,parent_id,body,subreddit, created_utc, score):\n",
        "  try:\n",
        "    query = f\"insert into table parent_reply(parent_id, comment_id, comment, subreddit, unix, score) values({parent_id}, {comment_id}, {body}, {subreddit}, {int(created_utc)}, {score})\"\n",
        "    add_query(query)\n",
        "  except Exception as e:\n",
        "    print(\"no parent insert error\")\n",
        "def insert_replace(comment_id,parent_id,parent_data,body,subreddit, created_utc, score):\n",
        "  try:\n",
        "    query = f\"update parent_reply set parent_id = {parent_id}, comment_id = {comemnt_id}, parent = {parent_data}, comment = {body}, subreddit = {subreddit}, unix = {int(created_utc)}, score = {score} where parent_id = {parent_id}\"\n",
        "    add_query(query)\n",
        "  except Exception as e:\n",
        "    print(\"insert replace error\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RR6nJ6dkj6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f'RC_{timeframe}',buffering = 1000) as f:\n",
        "  for row in f:\n",
        "    row_counter += 1\n",
        "    row = json.loads(row)\n",
        "    parent_id = row['parent_id']\n",
        "    body = format_data(row['body'])\n",
        "    created_utc = row[\"created_utc\"]\n",
        "    score = row[\"score\"]\n",
        "    comment_id = row[\"name\"]\n",
        "    subreddit = row['subreddit']\n",
        "    parent_data = find_parent(parent_id)\n",
        "    if acceptable(body):\n",
        "      if score >= 2:\n",
        "        existing_score = find_existing_parent(parent_id)\n",
        "        if existing_score:\n",
        "          if score > existing_score:\n",
        "            insert_replace(comment_id,parent_id,parent_data,body,subreddit, created_utc, score)\n",
        "        else:\n",
        "          if parent_data:\n",
        "            insert_has_parent(comment_id,parent_id,parent_data,body,subreddit, created_utc, score)\n",
        "            pairs += 1\n",
        "          else:\n",
        "            insert_no_parent(comment_id, parent_id, body,subreddit, created_utc, score)\n",
        "    if row_counter %100000 == 0 :\n",
        "      print(f\"rows = {row_counter} pairs = {pairs}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXVk9Ftwyje9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "timeframes = ['2015-08']\n",
        "for timeframe in timeframes:\n",
        "  limit = 5000\n",
        "  last_time = 0\n",
        "  read_len = 5000\n",
        "  count = 0\n",
        "  test_stat = False \n",
        "  while limit == read_len:\n",
        "    data = pd.read_sql(f\"select * from parent_reply where unix > {last_time} and parent not null and score > 0 order by unix asc limit {limit}\",connection)\n",
        "    last_time = data.tail(1)['unix'].values[0]\n",
        "    if not test_stat:\n",
        "      with open(\"test.from\", 'a', encoding = 'utf8') as f:\n",
        "        for content in data[\"parent\"].values:\n",
        "          f.write(content + '\\n')\n",
        "      with open(\"test.to\", 'a', encoding = 'utf8') as f:\n",
        "        for content in data[\"comment\"].values:\n",
        "          f.write(content + '\\n')\n",
        "      test_stat = True\n",
        "    else:\n",
        "      with open(\"train.from\", 'a', encoding = 'utf8') as f:\n",
        "        for content in data[\"parent\"].values:\n",
        "          f.write(content + '\\n')\n",
        "        for content in data['comment'].values:\n",
        "          f.write(content + '\\n') \n",
        "    count += 1\n",
        "    if count%10 == 0:\n",
        "      print(count * limit, 'rows')\n",
        "\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2V4jjBTOFcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    \n",
        "\n",
        "    text = text.lower()\n",
        "    \n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    \n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48nQ9ricfwXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def tokenize(inp, out):\n",
        "  tokenizer = Tokenizer(char_level = False)\n",
        "  \n",
        "  tokenizer.fit_on_texts(inp + out)\n",
        "  return tokenizer.texts_to_sequences(inp), tokenizer.texts_to_sequences(out), tokenizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQAT5FxFiXXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad(x, length = None):\n",
        "  if length is None:\n",
        "    length  = max([len(i) for i in x])\n",
        "    print(length)\n",
        "  return pad_sequences(x, maxlen = length, padding = 'post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBRLhPn_ocvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "  x.apply(clean_text)\n",
        "  y.apply(clean_text)\n",
        "  preprocess_x, preprocess_y, xtk = tokenize(x)\n",
        "  \n",
        "  preprocess_x = pad(preprocess_x)\n",
        "  preprocess_y = pad(preprocess_y)\n",
        "  preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "  return preprocess_x, preprocess_y, x_tk\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK5CpLkSq-X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pro_in, pro_out, eng_tk = preprocess(in_sentences, out_sentences)\n",
        "max_in_len = pro_in.shape[1]\n",
        "max_out_len = pro_out.shape[1]\n",
        "eng_vocab_size = len(eng_tk.word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfaT4c1OvjIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_to_text(output, tokenizer):\n",
        "  index_to_words = {id: word for word , id in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = \"<PAD>\"\n",
        "  return \" \".join([index_to_words[pr] for pr in np.argmax(output,1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z7vyTVC3CGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(input_shape, output_length, eng_voc_size):\n",
        "  lr = 1e-3\n",
        "  model = Sequential{\n",
        "      [\n",
        "       Embedding(eng_voc_size, 128, input_length = input_shape[1]),\n",
        "       Bidirectional(LSTM(128, return_sequences = False)),\n",
        "       RepeatVector(output_length),\n",
        "       Bidirectional(LSTM(128, return_sequences = True)),\n",
        "       TimeDistributed(Dense(eng_vocab_size, activation = 'softmax'))\n",
        "      ]\n",
        "  }\n",
        "  model.summary()\n",
        "  model.compile(loss = sparse_categorical_crossentropy, optimizer = Adam(lr), metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIiZOag1O-mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_x = pad(pro_in, max(max_in_len, max_out_len))\n",
        "output_y = pad(pro_out, max(max_out_len, max_in_len))\n",
        "fin_model = create_model(input_x.shape, max(max_out_len, max_in_len), eng_voc_size)\n",
        "history = fin_model.fit(input_x, output_y, batch_size = 256, epochs = 50, validation_split = 0.05)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U94jgg-wqqjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tagger(decoder_input_sentence):\n",
        "  bos = \"<BOS> \"\n",
        "  eos = \" <EOS>\"\n",
        "  final_target = [bos + text + eos for text in decoder_input_sentence] \n",
        "  return final_target\n",
        "\n",
        "decoder_inputs = tagger(decoder_input_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUucV1j9q2CD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# def vocab_creater(text_lists, VOCAB_SIZE):\n",
        "\n",
        "#   tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "#   tokenizer.fit_on_texts(text_lists)\n",
        "#   dictionary = tokenizer.word_index\n",
        "  \n",
        "#   word2idx = {}\n",
        "#   idx2word = {}\n",
        "#   for k, v in dictionary.items():\n",
        "#       if v < VOCAB_SIZE:\n",
        "#           word2idx[k] = v\n",
        "#           index2word[v] = k\n",
        "#       if v >= VOCAB_SIZE-1:\n",
        "#           continue\n",
        "          \n",
        "#   return word2idx, idx2word\n",
        "\n",
        "# word2idx, idx2word = vocab_creater(text_lists=encoder_input_text+decoder_input_text, VOCAB_SIZE=14999)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPVFo6u2q5ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.preprocessing.text import Tokenizer\n",
        "# VOCAB_SIZE = 14999\n",
        "\n",
        "# def text2seq(encoder_text, decoder_text, VOCAB_SIZE):\n",
        "\n",
        "#   tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "#   encoder_sequences = tokenizer.texts_to_sequences(encoder_text)\n",
        "#   decoder_sequences = tokenizer.texts_to_sequences(decoder_text)\n",
        "  \n",
        "#   return encoder_sequences, decoder_sequences\n",
        "\n",
        "# encoder_sequences, decoder_sequences = text2seq(encoder_text, decoder_text, VOCAB_SIZE) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GdzNQfmq_9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# def padding(encoder_sequences, decoder_sequences, MAX_LEN):\n",
        "  \n",
        "#   encoder_input_data = pad_sequences(encoder_sequences, maxlen=MAX_LEN, dtype='int32', padding='post', truncating='post')\n",
        "#   decoder_input_data = pad_sequences(decoder_sequences, maxlen=MAX_LEN, dtype='int32', padding='post', truncating='post')\n",
        "  \n",
        "#   return encoder_input_data, decoder_input_data\n",
        "\n",
        "# encoder_input_data, decoder_input_data = padding(encoder_sequences, decoder_sequences, MAX_LEN):\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Diz27ilrfS_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def seq2seq_model_builder(HIDDEN_DIM=300):\n",
        "    \n",
        "#     encoder_inputs = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
        "#     encoder_embedding = embed_layer(encoder_inputs)\n",
        "#     encoder_LSTM = LSTM(HIDDEN_DIM, return_state=True)\n",
        "#     encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
        "    \n",
        "#     decoder_inputs = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
        "#     decoder_embedding = embed_layer(decoder_inputs)\n",
        "#     decoder_LSTM = LSTM(HIDDEN_DIM, return_state=True, return_sequences=True)\n",
        "#     decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n",
        "    \n",
        "#     # dense_layer = Dense(VOCAB_SIZE, activation='softmax')\n",
        "#     outputs = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))(decoder_outputs)\n",
        "#     model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "    \n",
        "#     return model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}